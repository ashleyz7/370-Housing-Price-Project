{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import operator\n",
    "# from pandas.plotting import scatter_matrix\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler       # scaling data\n",
    "from sklearn.model_selection import train_test_split # splitting data\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV     # for grid search\n",
    "from sklearn.pipeline import make_pipeline           # for making pipelines\n",
    "# from sklearn.neighbors import KNeighborsRegressor    # regressor\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.ensemble import AdaBoostRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the en csv files and clean up the column names\n",
    "all_data = read_csv('data/data.csv')\n",
    "all_data.isnull().sum()\n",
    "for col_name in all_data.columns:\n",
    "    new_col_name = col_name.split(None, 1)[1:]\n",
    "    new_col_name = ''.join(new_col_name)\n",
    "    all_data.rename(columns = {col_name:new_col_name[:-33]}, inplace = True)\n",
    "all_data.columns = all_data.columns.str.replace('-', ' ')\n",
    "all_data.columns = all_data.columns.str.replace(' ', '_')\n",
    "\n",
    "all_data = all_data[pd.notnull(all_data['Median_Listing_Price___All_Homes'])]\n",
    "##### renaming outcome and splitting feature & outcome since we do not want to scale outcomes\n",
    "all_data = all_data.rename(index=str, columns={\"Median_Listing_Price___All_Homes\": \"outcome\"})\n",
    "outcomes = pd.DataFrame(all_data.outcome)\n",
    "all_data.drop('outcome', axis=1, inplace=True)\n",
    "#all_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add two new columns that individually record year and month of that row\n",
    "month = []\n",
    "year = []\n",
    "for date in all_data['']:\n",
    "    month.append(date[0])\n",
    "    year.append(date[-4:])\n",
    "\n",
    "all_data['month'] = month\n",
    "all_data['year'] = year\n",
    "all_data = all_data.drop('', axis=1)\n",
    "#all_data = all_data.drop('Zillow_Home_Value_Index_-_Top_Tier_-_Year-Over...', axis=1)\n",
    "\n",
    "all_data['month'] = all_data['month'].astype('int64')\n",
    "all_data['year']=all_data['year'].astype('int64')\n",
    "\n",
    "col_name = all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109, 88)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handling missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "impu = SimpleImputer()\n",
    "all_data = pd.DataFrame(impu.fit_transform(all_data))\n",
    "all_data.columns = col_name\n",
    "#outcomes.shape\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 88)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############### We don't want to scale the outcome variable, only features\n",
    "############### Also make sure which features to standardize or normalize\n",
    "# #standardized\n",
    "\n",
    "# from sklearn import preprocessing\n",
    "# # Get column names first\n",
    "# names = all_data.columns\n",
    "# # Create the Scaler object\n",
    "# std_scaler = preprocessing.StandardScaler()\n",
    "# # Fit your data on the scaler object\n",
    "# scaled_data = std_scaler.fit_transform(all_data)\n",
    "# scaled_data = pd.DataFrame(scaled_data, columns=names)\n",
    "\n",
    "#normalize\n",
    "from sklearn import preprocessing\n",
    "# Normalize total_bedrooms column\n",
    "names = all_data.columns\n",
    "scaled_data = preprocessing.normalize(all_data)\n",
    "scaled_data = pd.DataFrame(scaled_data, columns=names)\n",
    "scaled_data = scaled_data[(scaled_data > 0).all(1)] ############ What is this for? removed some rows, breaks train split\n",
    "scaled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Home_Sold_As_Foreclosure___Ratio___All_Homes         1.702905e-12\n",
       "Inventory_Measure_(Public)                           2.940434e-08\n",
       "Inventory_Measure___SSA_(Public)                     2.352524e-08\n",
       "Listings_Price_Cuts_(SA)_All_Homes                   2.483968e-12\n",
       "Listings_Price_Cuts_(SA)_Condominiums                3.487139e-12\n",
       "Listings_Price_Cuts_(SA)_Single_Family_Residence     2.259996e-12\n",
       "Median_Listing_Price___Condo/Co_op                   2.233643e-05\n",
       "Median_Listing_Price___Duplex/Triplex                9.804376e-04\n",
       "Median_Listing_Price___Five_Or_More_Bedrooms         1.520013e-03\n",
       "Median_Listing_Price___Four_Bedrooms                 3.016368e-04\n",
       "Median_Listing_Price___One_Bedroom                   6.589856e-05\n",
       "Median_Listing_Price___Single_Family_Residence       3.647415e-05\n",
       "Median_Listing_Price___Three_Bedrooms                1.762007e-05\n",
       "Median_Listing_Price___Two_Bedrooms                  2.515699e-05\n",
       "Median_Listing_Price_Per_Square_Foot___All_Homes     7.148689e-12\n",
       "Median_Listing_Price_Per_Square_Foot___Condo/C...    3.661752e-11\n",
       "Median_Listing_Price_Per_Square_Foot___Duplex/...    1.023431e-09\n",
       "Median_Listing_Price_Per_Square_Foot___Five_Or...    1.928439e-11\n",
       "Median_Listing_Price_Per_Square_Foot___Four_Be...    1.562446e-11\n",
       "Median_Listing_Price_Per_Square_Foot___One_Bed...    8.344221e-11\n",
       "Median_Listing_Price_Per_Square_Foot___Single_...    5.942044e-12\n",
       "Median_Listing_Price_Per_Square_Foot___Three_B...    5.314960e-12\n",
       "Median_Listing_Price_Per_Square_Foot___Two_Bed...    1.582449e-11\n",
       "Median_Price_Cut_Dollar___All_Homes                  2.025147e-06\n",
       "Median_Price_Cut_Dollar___Condo                      1.780911e-06\n",
       "Median_Price_Cut_Dollar___Single_Family_Residence    2.149546e-06\n",
       "Median_Price_Of_Reduction___All_Homes                1.275882e-13\n",
       "Median_Price_Of_Reduction___Condo                    1.866933e-13\n",
       "Median_Price_Of_Reduction___Single_Family_Resi...    1.184401e-13\n",
       "Median_Rental_Price___All_Homes                      6.079990e-09\n",
       "                                                         ...     \n",
       "Percent_Of_Homes_Selling_For_Gain___All_Homes        3.457205e-11\n",
       "Percent_Of_Homes_Selling_For_Loss___All_Homes        1.829422e-11\n",
       "Percent_Of_Listings_With_Price_Reductions___Al...    3.320932e-12\n",
       "Percent_Of_Listings_With_Price_Reductions___Condo    4.135091e-12\n",
       "Percent_Of_Listings_With_Price_Reductions___Si...    3.166327e-12\n",
       "Percent_Transactions_That_Are_Previously_Forec...    3.119514e-13\n",
       "Price_To_Rent_Ratio___All_Homes                      1.074295e-12\n",
       "Turnover___All_Homes                                 3.505935e-13\n",
       "Unsold_Renos___All_Homes                             2.944496e-11\n",
       "Zillow_Home_Value_Index___All_Homes                  3.867754e-05\n",
       "Zillow_Home_Value_Index___Bottom_Tier_Year_Ove...    2.998849e-16\n",
       "Zillow_Home_Value_Index___Bottom_Tier                6.801812e-05\n",
       "Zillow_Home_Value_Index___Condo                      4.511171e-05\n",
       "Zillow_Home_Value_Index___Five_Or_More_Bedrooms      7.034305e-05\n",
       "Zillow_Home_Value_Index___Four_Bedrooms              6.239996e-05\n",
       "Zillow_Home_Value_Index___Middle_Tier___Year_O...    2.392635e-16\n",
       "Zillow_Home_Value_Index___Middle_Tier                3.871318e-05\n",
       "Zillow_Home_Value_Index___One_Bedroom                3.045913e-05\n",
       "Zillow_Home_Value_Index___Single_Family_Residence    4.310944e-05\n",
       "Zillow_Home_Value_Index___Three_Bedrooms             3.868783e-05\n",
       "Zillow_Home_Value_Index___Top_Tier___Year_Over...    1.775279e-16\n",
       "Zillow_Home_Value_Index___Top_Tier                   5.368807e-05\n",
       "Zillow_Home_Value_Index___Two_Bedrooms               3.844476e-05\n",
       "Zillow_Rental_Index___All_Homes_Plus_Multi_Family    6.493875e-09\n",
       "Zillow_Rental_Index___All_Homes                      6.716881e-09\n",
       "Zillow_Rental_Index___Multi_Family_Residence         5.187856e-09\n",
       "Zillow_Rental_Index___Single_Family_Residence        8.251718e-09\n",
       "Zillow_Rental_Index_Per_Square_Foot___All_Homes      3.571311e-15\n",
       "month                                                1.478909e-12\n",
       "year                                                 2.593701e-08\n",
       "Length: 88, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### checking variance, for variance selector we need to specify a threshold (e.g. 0.01) to actually remove features\n",
    "####### or use along with select percentile\n",
    "scaled_data.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Home_Sold_As_Foreclosure___Ratio___All_Homes         float64\n",
       "Inventory_Measure_(Public)                           float64\n",
       "Inventory_Measure___SSA_(Public)                     float64\n",
       "Listings_Price_Cuts_(SA)_All_Homes                   float64\n",
       "Listings_Price_Cuts_(SA)_Condominiums                float64\n",
       "Listings_Price_Cuts_(SA)_Single_Family_Residence     float64\n",
       "Median_Listing_Price___All_Homes                     float64\n",
       "Median_Listing_Price___Condo/Co_op                   float64\n",
       "Median_Listing_Price___Duplex/Triplex                float64\n",
       "Median_Listing_Price___Five_Or_More_Bedrooms         float64\n",
       "Median_Listing_Price___Four_Bedrooms                 float64\n",
       "Median_Listing_Price___One_Bedroom                   float64\n",
       "Median_Listing_Price___Single_Family_Residence       float64\n",
       "Median_Listing_Price___Three_Bedrooms                float64\n",
       "Median_Listing_Price___Two_Bedrooms                  float64\n",
       "Median_Listing_Price_Per_Square_Foot___All_Homes     float64\n",
       "Median_Listing_Price_Per_Square_Foot___Condo/C...    float64\n",
       "Median_Listing_Price_Per_Square_Foot___Duplex/...    float64\n",
       "Median_Listing_Price_Per_Square_Foot___Five_Or...    float64\n",
       "Median_Listing_Price_Per_Square_Foot___Four_Be...    float64\n",
       "Median_Listing_Price_Per_Square_Foot___One_Bed...    float64\n",
       "Median_Listing_Price_Per_Square_Foot___Single_...    float64\n",
       "Median_Listing_Price_Per_Square_Foot___Three_B...    float64\n",
       "Median_Listing_Price_Per_Square_Foot___Two_Bed...    float64\n",
       "Median_Price_Cut_Dollar___All_Homes                  float64\n",
       "Median_Price_Cut_Dollar___Condo                      float64\n",
       "Median_Price_Cut_Dollar___Single_Family_Residence    float64\n",
       "Median_Price_Of_Reduction___All_Homes                float64\n",
       "Median_Price_Of_Reduction___Condo                    float64\n",
       "Median_Price_Of_Reduction___Single_Family_Resi...    float64\n",
       "                                                      ...   \n",
       "Percent_Of_Homes_Selling_For_Gain___All_Homes        float64\n",
       "Percent_Of_Homes_Selling_For_Loss___All_Homes        float64\n",
       "Percent_Of_Listings_With_Price_Reductions___Al...    float64\n",
       "Percent_Of_Listings_With_Price_Reductions___Condo    float64\n",
       "Percent_Of_Listings_With_Price_Reductions___Si...    float64\n",
       "Percent_Transactions_That_Are_Previously_Forec...    float64\n",
       "Price_To_Rent_Ratio___All_Homes                      float64\n",
       "Turnover___All_Homes                                 float64\n",
       "Unsold_Renos___All_Homes                             float64\n",
       "Zillow_Home_Value_Index___All_Homes                  float64\n",
       "Zillow_Home_Value_Index___Bottom_Tier_Year_Ove...    float64\n",
       "Zillow_Home_Value_Index___Bottom_Tier                float64\n",
       "Zillow_Home_Value_Index___Condo                      float64\n",
       "Zillow_Home_Value_Index___Five_Or_More_Bedrooms      float64\n",
       "Zillow_Home_Value_Index___Four_Bedrooms              float64\n",
       "Zillow_Home_Value_Index___Middle_Tier___Year_O...    float64\n",
       "Zillow_Home_Value_Index___Middle_Tier                float64\n",
       "Zillow_Home_Value_Index___One_Bedroom                float64\n",
       "Zillow_Home_Value_Index___Single_Family_Residence    float64\n",
       "Zillow_Home_Value_Index___Three_Bedrooms             float64\n",
       "Zillow_Home_Value_Index___Top_Tier___Year_Over...    float64\n",
       "Zillow_Home_Value_Index___Top_Tier                   float64\n",
       "Zillow_Home_Value_Index___Two_Bedrooms               float64\n",
       "Zillow_Rental_Index___All_Homes_Plus_Multi_Family    float64\n",
       "Zillow_Rental_Index___All_Homes                      float64\n",
       "Zillow_Rental_Index___Multi_Family_Residence         float64\n",
       "Zillow_Rental_Index___Single_Family_Residence        float64\n",
       "Zillow_Rental_Index_Per_Square_Foot___All_Homes      float64\n",
       "month                                                float64\n",
       "year                                                 float64\n",
       "Length: 89, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing features with low variance\n",
    "def variance_threshold_selector(data):\n",
    "    sel = VarianceThreshold() ###### need to specify threshold value or it won't remove\n",
    "    sel.fit(data)\n",
    "    return data[data.columns[sel.get_support(indices=True)]]\n",
    "\n",
    "\n",
    "var_thrhold = variance_threshold_selector(scaled_data) \n",
    "\n",
    "\n",
    "scaled_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-3a869fc400b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGradientBoostingRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mgbrfit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientBoostingRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ls'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSelectFromModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgbrfit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#train_x = model.transform(train_x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_x' is not defined"
     ]
    }
   ],
   "source": [
    "#Univariate feature selection\n",
    "#def univariate_feature_selector(data, k=7):\n",
    "#    uni_select = SelectKBest(chi2, k)\n",
    "#    uni_select.fit_transform(data,data.Median_Listing_Price___All_Homes)\n",
    "#    return data[data.columns[uni_select.get_support(indices=True)]]\n",
    "\n",
    "#house_uni = univariate_feature_selector(scaled_data, k=7)\n",
    "\n",
    "#Feature importance based off of gbr\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrfit = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=1, random_state=0, loss='ls').fit(train_x, train_y)\n",
    "model = SelectFromModel(gbrfit, prefit=True)\n",
    "#train_x = model.transform(train_x)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [76, 109]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-4c504b3c7704>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0moutcomes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# outcome\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m \u001b[1;31m# percentage of data to use as the test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2182\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2184\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2186\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 235\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [76, 109]"
     ]
    }
   ],
   "source": [
    "# Split data into test and training data with a test size of 30% (.3)\n",
    "from sklearn.model_selection import train_test_split # typically done at the start\n",
    "train_x, test_x, train_y, test_y = train_test_split(\n",
    "    scaled_data, # features\n",
    "    outcomes, # outcome\n",
    "    random_state = 11,\n",
    "    test_size=0.3 # percentage of data to use as the test set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
